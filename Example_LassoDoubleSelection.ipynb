{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmDvtINL-rf3"
      },
      "source": [
        "# Example Lasso for double selection\n",
        "*Sep 2022*\n",
        "\n",
        "-----------------\n",
        "\n",
        "This is an example of how to use LASSO for model selection when we are \n",
        "interested in a causal interpretation of the variables. In particularly \n",
        "we are interested in explaining the effects of protected areas (*wdpa_2017*) on deforestation. Note, this example should be understood only as in illustration of the approach, for actually deriving an causal effect other aspects might need to be considered as well.\n",
        "\n",
        "### For further details on the approach see:\n",
        "\n",
        "**Double Selection: **\n",
        "Belloni, Alexandre, Victor Chernozhukov, and Christian Hansen. 2014. “High-Dimensional Methods and Inference on Structural and Treatment Effects.” The Journal of Economic Perspectives 28 (2): 29–50.\n",
        "\n",
        "*In case you are interested in an R implementation of the Double selection approach check out the notebook prepared from a similar lecture:\n",
        "https://github.com/hstorm/LASSO_model_selection_lecture*\n",
        "\n",
        "*Question contact: Hugo Storm (hugo.storm@ilr.uni-bonn.de)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuO5pBZNsAAl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "# import seaborn for visualization\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sc\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn import linear_model\n",
        "\n",
        "from sklearn.linear_model import lasso_path, enet_path\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LassoCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FEmxcTHsbSj",
        "outputId": "1292ba01-20a5-42c6-fbc1-e4158bebda3c"
      },
      "outputs": [],
      "source": [
        "# run this cell only once if you don't have wget installed\n",
        "# its assumed you are using windows and have python installed\n",
        "# only needed if you are running the notebook locally\n",
        "# %pip install wget\n",
        "#if not os.path.isfile('brazil_all_data_v2.gz'):\n",
        "#    !python -m wget  https://ilr-ml.s3.eu-central-1.amazonaws.com/brazil_all_data_v2.gz\n",
        "# Download data only once and make sure it is in the same folder as the notebook\n",
        "\n",
        "# check if brazil_all_data_v2.gz is available in the current folder and if not, download it\n",
        "\n",
        "if not os.path.isfile('brazil_all_data_v2.gz'):\n",
        "    !wget  https://ilr-ml.s3.eu-central-1.amazonaws.com/brazil_all_data_v2.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B-8nLNOsiYB"
      },
      "outputs": [],
      "source": [
        "# load data into dataframe\n",
        "df = pd.read_parquet('brazil_all_data_v2.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WHivjoiszDJ"
      },
      "outputs": [],
      "source": [
        "# Define target (dependent) variable (% forest cover for 2018)\n",
        "strY = 'perc_treecover'\n",
        "\n",
        "# Get name of treatment variabel\n",
        "strTreat =  'wdpa_2017' \n",
        "\n",
        "# Define a list of exognous features names \n",
        "lstExog = [\n",
        "  'population_2015',\n",
        "  'chirps_2017',\n",
        "  'maize',\n",
        "  'soy',\n",
        "  'sugarcane',\n",
        "  'perm_water',\n",
        "  'travel_min',\n",
        "  'cropland',\n",
        "  'mean_elev',\n",
        "  'sd_elev',\n",
        "  'near_road',\n",
        "  'chirps_2017_lag_1st_order',\n",
        "  'population_2015_lag_1st_order',\n",
        "  'maize_lag_1st_order',\n",
        "  'soy_lag_1st_order',\n",
        "  'sugarcane_lag_1st_order',\n",
        "  'perc_treecover_lag_1st_order',\n",
        "  'perm_water_lag_1st_order',\n",
        "  'travel_min_lag_1st_order',\n",
        "  'cropland_lag_1st_order',\n",
        "  'mean_elev_lag_1st_order',\n",
        "  'sd_elev_lag_1st_order',\n",
        "  'near_road_lag_1st_order',\n",
        " ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiVoVspu8zfD"
      },
      "outputs": [],
      "source": [
        "# Select the target variable \n",
        "Y_all = df[strY]\n",
        "\n",
        "# Get all exogenous features\n",
        "X_exog_all =  df[lstExog]\n",
        "\n",
        "# Get treatment variable D\n",
        "D_all = df[strTreat]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb6nm_Xv8HuJ"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test using only the the observations \n",
        "# without protected areas\n",
        "X_train_raw, X_test_raw, Y_train, Y_test, D_train, D_test = train_test_split(X_exog_all, Y_all, D_all, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHqPEfJ79XsC"
      },
      "outputs": [],
      "source": [
        "# Scale data to 0-1 range using sklearn MinMaxScalar object \n",
        "# (see: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) \n",
        "scaler = MinMaxScaler()\n",
        "# Use only the train data to fit the MinMaxScalar \n",
        "scaler.fit(X_train_raw)\n",
        "\n",
        "# Apply the MinMax transformation to the train and test data \n",
        "X_train = scaler.transform(X_train_raw)\n",
        "X_test = scaler.transform(X_test_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trRvBhWPtqZ-",
        "outputId": "9b003593-964b-4094-afb4-5c7d55c3b124"
      },
      "outputs": [],
      "source": [
        "# Use an sklearn function to generate polynomials of order 2 \n",
        "# (square terms and interaction terms)\n",
        "# (see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures.get_feature_names)\n",
        "poly = PolynomialFeatures(2, interaction_only=True)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "print('Total number of avaliable features',X_train_poly.shape[1])\n",
        "lstFeatures = poly.get_feature_names_out()\n",
        "# Show feature names\n",
        "# list(lstFeatures)\n",
        "\n",
        "# Transform to pandas df for better readability\n",
        "X_train_poly =  pd.DataFrame(X_train_poly, columns=lstFeatures, index=X_train_raw.index)\n",
        "X_test_poly =  pd.DataFrame(X_test_poly, columns=lstFeatures, index=X_test_raw.index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-saNFJYkxCz"
      },
      "outputs": [],
      "source": [
        "# Transform to pandas df for better readability\n",
        "X_train =  pd.DataFrame(X_train, columns=lstExog, index=X_train_raw.index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfDXy03DpNWM"
      },
      "outputs": [],
      "source": [
        "# Use this cell to use the polynomial features, if not executing this \n",
        "# only  the original variables (no square term, \n",
        "# no interaction terms) are considered below\n",
        "\n",
        "#X_train = X_train_poly.iloc[:,1:] # \"1:\" to exclude constant\n",
        "#lstExog = lstFeatures[1:] # \"1:\" to exclude constant\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JO36C96_dqd"
      },
      "source": [
        "### Perpare function for finding alpha "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjowDs-VoY4a",
        "outputId": "d58e386e-46be-46e0-990e-87f85ddc1325"
      },
      "outputs": [],
      "source": [
        "lstAlpha = np.logspace(-6, -4, num = 10, base = 2)\n",
        "lstAlpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "506FyPcCIo0Q"
      },
      "outputs": [],
      "source": [
        "def LassoGetBestAlpha(X,Y,lstAlpha, plot=True):\n",
        "\n",
        "  modLasso = LassoCV(fit_intercept=True, alphas = lstAlpha)\n",
        "  modLasso.fit(X, Y)  \n",
        "\n",
        "  # Create df to hold mse_path along with alphas and std of MSE \n",
        "  dfMse = pd.DataFrame([modLasso.alphas_, \n",
        "                      np.mean(modLasso.mse_path_,axis=1),\n",
        "                       np.std(modLasso.mse_path_,axis=1)], \n",
        "                     index=['alphas','mean_mse','std_mse']).transpose()\n",
        "\n",
        "  # Find model with lowest MSE\n",
        "  minMse = dfMse.loc[dfMse['mean_mse'].min()==dfMse['mean_mse']]\n",
        "\n",
        "  alphaBest = minMse['alphas'].iloc[0]\n",
        "  mseBest = minMse['mean_mse'].iloc[0]\n",
        "  mseStdBest = minMse['std_mse'].iloc[0]\n",
        "\n",
        "  # Find the largest alpha that is within one std of the model with the lowest MSE\n",
        "  alpha1std = dfMse.loc[dfMse['mean_mse']<(mseBest+mseStdBest),'alphas'].max()\n",
        "\n",
        "  if plot:\n",
        "    plt.vlines(np.log(alphaBest), modLasso.mse_path_.min(),modLasso.mse_path_.max(),linestyles='dashed',label='alphaBest' )\n",
        "    plt.vlines(np.log(alpha1std), modLasso.mse_path_.min(),modLasso.mse_path_.max(),linestyles='dotted',label='alpha1std')\n",
        "    plt.errorbar(np.log(modLasso.alphas_),np.mean(modLasso.mse_path_,axis=1), yerr=np.std(modLasso.mse_path_,axis=1));\n",
        "\n",
        "  return alphaBest, alpha1std, dfMse \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfM_J7kLlngB"
      },
      "source": [
        "### OLS on all variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "GcFS-Nejlmfu",
        "outputId": "4e3b3c29-6b1e-436e-8d3e-b1fefb261b73"
      },
      "outputs": [],
      "source": [
        "# Run Ols with all variables\n",
        "modOlsFull = LinearRegression(fit_intercept=True)\n",
        "modOlsFull.fit(pd.concat([X_train,D_train], axis=1), Y_train)\n",
        "\n",
        "dfRes = pd.DataFrame(modOlsFull.coef_,index=lstExog+[strTreat], columns=['FullModelOls'])\n",
        "dfRes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1PRiKTIl9_3"
      },
      "source": [
        "### Post-Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "e8GyDUrOKoDY",
        "outputId": "cfb1b72d-7b42-425a-ef8b-e7234fdc15b3"
      },
      "outputs": [],
      "source": [
        "# Run Post-Lasso\n",
        "\n",
        "# Find best alpha\n",
        "alphaBest, alpha1std, dfMse = LassoGetBestAlpha(pd.concat([X_train,D_train], axis=1), Y_train,lstAlpha, plot=True)\n",
        "\n",
        "# Run lasso using alphaBest\n",
        "modPostLasso_best = Lasso(fit_intercept=True, alpha = alphaBest)\n",
        "modPostLasso_best.fit(pd.concat([X_train,D_train], axis=1), Y_train)\n",
        "\n",
        "# Run lasso using alpha1std\n",
        "modPostLasso_best1std = Lasso(fit_intercept=True, alpha = alpha1std)\n",
        "modPostLasso_best1std.fit(pd.concat([X_train,D_train], axis=1), Y_train)\n",
        "\n",
        "# Create df to hold coef\n",
        "dfPostLasso = pd.DataFrame([modPostLasso_best.coef_,\n",
        "                      modPostLasso_best1std.coef_],\n",
        "                     columns=lstExog+[strTreat],\n",
        "                     index=['PostLasso_best',\n",
        "                            'PostLasso_best1std']).replace(0,np.nan).transpose()\n",
        "\n",
        "lstVarSelect_Post_best = list(dfPostLasso[['PostLasso_best']].dropna().index)\n",
        "lstVarSelect_Post_1std = list(dfPostLasso[['PostLasso_best1std']].dropna().index)\n",
        "\n",
        "# Remove treatment variable from list\n",
        "lstVarSelect_Post_best.remove(strTreat)\n",
        "lstVarSelect_Post_1std.remove(strTreat)\n",
        "print('Selected variables \"best\"',lstVarSelect_Post_best)\n",
        "print('Selected variables \"1std\"',lstVarSelect_Post_1std)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "YmY5AEAvlRLp",
        "outputId": "9854d141-d29c-4106-eba9-263ab25c0130"
      },
      "outputs": [],
      "source": [
        "# Run \"post\"-OLS with best\n",
        "modOlsPost_best = LinearRegression(fit_intercept=True)\n",
        "modOlsPost_best.fit(pd.concat([X_train[lstVarSelect_Post_best],D_train], axis=1), Y_train)\n",
        "\n",
        "# Run \"post\"-OLS with 1std\n",
        "modOlsPost_1std = LinearRegression(fit_intercept=True)\n",
        "modOlsPost_1std.fit(pd.concat([X_train[lstVarSelect_Post_1std],D_train], axis=1), Y_train)\n",
        "\n",
        "# Add estimated coef to dfRes\n",
        "dfRes.loc[lstVarSelect_Post_best+[strTreat],'OlsPost_best'] = modOlsPost_best.coef_\n",
        "dfRes.loc[lstVarSelect_Post_1std+[strTreat],'OlsPost_1std'] = modOlsPost_1std.coef_\n",
        "dfRes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IEt9fFRL2H-"
      },
      "source": [
        "### Lasso Double selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "uq-QSrk0NRot",
        "outputId": "03810657-c2d2-4b84-d195-0bc6e8a4ac6c"
      },
      "outputs": [],
      "source": [
        "# Run Lasso on first stage (regression outcome on all exogenous, except treatment)\n",
        "\n",
        "# Find best alpha\n",
        "alphaBest_1st, alpha1std_1st, dfMse_1st = LassoGetBestAlpha(X_train, Y_train,lstAlpha, plot=True)\n",
        "\n",
        "# Run lasso for first stage (1st) using alphaBest\n",
        "modLasso_best_1st = Lasso(fit_intercept=True, alpha = alphaBest_1st)\n",
        "modLasso_best_1st.fit(X_train, Y_train)\n",
        "# Run lasso for first stage (1st) using alpha1std\n",
        "modLasso_best1std_1st = Lasso(fit_intercept=True, alpha = alpha1std_1st)\n",
        "modLasso_best1std_1st.fit(X_train, Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "GN29rM4RNuCA",
        "outputId": "d2dfb9ea-92f4-4fd1-b63e-55a51fea19f8"
      },
      "outputs": [],
      "source": [
        "# Create df to hold coef\n",
        "dfRes_1st = pd.DataFrame([modLasso_best_1st.coef_,\n",
        "                      modLasso_best1std_1st.coef_],\n",
        "                     columns=lstExog,\n",
        "                     index=['Lasso_best_1st',\n",
        "                            'Lasso_best1std_1st']).replace(0,np.nan).transpose()\n",
        "dfRes_1st"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "WUx7QRA9Lc-a",
        "outputId": "d0f549c8-bac3-4981-b752-b4f57915fd97"
      },
      "outputs": [],
      "source": [
        "# Run Lasso on first stage (regression outcome on all exogenous, except treatment)\n",
        "\n",
        "# Find best alpha\n",
        "alphaBest_2st, alpha1std_2st, dfMse_2st = LassoGetBestAlpha(X_train, D_train,lstAlpha, plot=True)\n",
        "\n",
        "# Run lasso for second stage (2st) using alphaBest\n",
        "modLasso_best_2st = Lasso(fit_intercept=True, alpha = alphaBest_2st)\n",
        "modLasso_best_2st.fit(X_train, D_train)\n",
        "# Run lasso for second stage (2st) using alpha2std\n",
        "modLasso_best1std_2st = Lasso(fit_intercept=True, alpha = alpha1std_2st)\n",
        "modLasso_best1std_2st.fit(X_train, D_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "2OqeQ6huOLXA",
        "outputId": "f1d85a87-47e1-4b2b-d6ab-30cbb689bf70"
      },
      "outputs": [],
      "source": [
        "# Create df to hold coef\n",
        "dfRes_2st = pd.DataFrame([modLasso_best_2st.coef_,\n",
        "                      modLasso_best1std_2st.coef_],\n",
        "                     columns=lstExog,\n",
        "                     index=['Lasso_best_2st',\n",
        "                            'Lasso_best1std_2st']).replace(0,np.nan).transpose()\n",
        "dfRes_2st"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M6ErI8IOXBK",
        "outputId": "d6cbc017-d145-4b0b-bb06-28ba9fc4a046"
      },
      "outputs": [],
      "source": [
        "# Run Lasso on union of set selected in first and second stage\n",
        "\n",
        "lstVarSelect_best_1st = list(dfRes_1st[['Lasso_best_1st']].dropna().index)\n",
        "lstVarSelect_best_2st = list(dfRes_2st[['Lasso_best_2st']].dropna().index)\n",
        "\n",
        "lstVarSelect_1std_1st = list(dfRes_1st[['Lasso_best1std_1st']].dropna().index)\n",
        "lstVarSelect_1std_2st = list(dfRes_2st[['Lasso_best1std_2st']].dropna().index)\n",
        "\n",
        "# Get union of the two list (using python set() function)\n",
        "lstVarSelect_best_Union = list(set(lstVarSelect_best_1st+lstVarSelect_best_2st))\n",
        "lstVarSelect_1std_Union = list(set(lstVarSelect_1std_1st+lstVarSelect_1std_2st))\n",
        "print('Selected variables \"best\"',lstVarSelect_best_Union)\n",
        "print('Selected variables \"1std\"',lstVarSelect_1std_Union)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "q1CSbCzufaCs",
        "outputId": "861338af-25ab-4b3b-a515-19deacf6e739"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Run Ols with selected variables\n",
        "modOlsDouble_best = LinearRegression(fit_intercept=True)\n",
        "modOlsDouble_best.fit(pd.concat([X_train[lstVarSelect_best_Union],D_train], axis=1), Y_train)\n",
        "\n",
        "modOlsDouble_1std = LinearRegression(fit_intercept=True)\n",
        "modOlsDouble_1std.fit(pd.concat([X_train[lstVarSelect_1std_Union],D_train], axis=1), Y_train)\n",
        "\n",
        "dfRes.loc[lstVarSelect_best_Union+[strTreat],'DoubleLasso_OLS_best'] = modOlsDouble_best.coef_\n",
        "dfRes.loc[lstVarSelect_1std_Union+[strTreat],'DoubleLasso_OLS_1std'] = modOlsDouble_1std.coef_\n",
        "dfRes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkSVPjC2p4Pu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
